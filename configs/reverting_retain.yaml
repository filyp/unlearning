model_id: meta-llama/Llama-3.2-1B
category: bio
split: dev_T
unlearning_loss_fn: neg_cross_entropy
unlearning_steps: 300
unlearning_rate: 1e-3
retaining_rate: 4e-3
# percentile: None
num_disruption_batches: 8
tokenizer:
    max_length: 128
    padding: true
    truncation: true
    return_tensors: pt
target_modules:
    - gate_proj
    - up_proj
    # - down_proj
    - q_proj
    - k_proj
    - o_proj
    # - v_proj