model_id: meta-llama/Llama-3.2-1B
category: bio
split: dev_T
unlearning_loss_fn: neg_cross_entropy
masking: no_mask
unlearning_rate: 9e-2
use_related_retain: false
# percentile: None
num_disruption_batches: 16
tokenizer:
    max_length: 128
    padding: true
    truncation: true
    return_tensors: pt
