model_id: meta-llama/Llama-3.2-1B
category: bio
split: dev_T
split_disr: dev_V
unlearning_loss_fn: correct_logit_minus_avg

retain_only_in_reverting_direction: true
unlearning_method: normal  # normal, common_core, only_answer_tokens
masking_method: null  # null, mask_out_answer_without_context

num_epochs: 20
unlearning_rate: 3e-3
# percentile: None
num_disruption_batches: 16
tokenizer:
    max_length: 128
    padding: true
    truncation: true
    return_tensors: pt
target_modules:
    - gate_proj
    - up_proj
    # - down_proj
    - q_proj
    - k_proj
    - o_proj
    # - v_proj